<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>DiverseVAR: Diversity Has Always Been There in Your Visual Autoregressive Models</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- ç½‘é¡µæ ‡ç­¾çš„å°å›¾æ ‡ï¼ˆfaviconï¼‰ï¼Œè¯·ä¿è¯ DiverseVAR.png åœ¨åŒä¸€ç›®å½•ä¸‹ -->
  <!-- <link rel="icon" type="image/png" href="DiverseVAR.png"> -->
  <!-- <link rel="shortcut icon" type="image/png" href="DiverseVAR.png"> -->
  <link rel="icon" href="https://github.githubassets.com/favicons/favicon.png">

  <style>
    * {
      box-sizing: border-box;
    }
    body {
      margin: 0;
      padding: 0;
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
      line-height: 1.6;
      color: #222;
      background-color: #fafafa;
    }
    a {
      color: #0066cc;
      text-decoration: none;
    }
    a:hover {
      text-decoration: underline;
    }
    header {
      padding: 32px 16px 24px;
      border-bottom: 1px solid #eee;
      background: #ffffff;
    }
    .container {
      max-width: 980px;
      margin: 0 auto;
      padding: 0 16px;
    }

    /* åŸæ¥çš„ .nav æ ·å¼å·²åˆ é™¤ */

    .hero {
      text-align: center;
    }
    .hero h1 {
      font-size: 2.5rem;
      margin: 8px 0;
    }
    .hero h3 {
      font-size: 1.25rem;
      font-weight: 500;
      margin: 8px 0 16px;
    }
    .authors {
      font-size: 0.95rem;
      margin-bottom: 8px;
    }
    .affiliations {
      font-size: 0.9rem;
      color: #555;
      margin-bottom: 12px;
    }
    .badges {
      margin-top: 12px;
    }
    main {
      padding: 24px 0 40px;
    }
    section {
      margin-top: 40px;
      background: #ffffff;
      border-radius: 10px;
      padding: 24px 20px;
      box-shadow: 0 1px 3px rgba(0,0,0,0.04);
    }
    section h2 {
      margin-top: 0;
      margin-bottom: 12px;
      font-size: 1.4rem;
      border-left: 4px solid #0070f3;
      padding-left: 8px;
    }
    ul {
      padding-left: 20px;
    }
    .figure {
      text-align: center;
      margin-top: 16px;
      font-size: 0.9rem;
      color: #555;
    }
    .figure img {
      max-width: 100%;
      border-radius: 8px;
      border: 1px solid #eee;
    }
    
    table {
      width: 100%;
      border-collapse: collapse;
      margin-top: 12px;
      font-size: 0.9rem;
    }
    table thead {
      background-color: #f3f4f6;
    }
    table th,
    table td {
      padding: 8px;
      border: 1px solid #e5e7eb;
    }
    /* ç¬¬ 1 åˆ—ï¼šDatasetï¼Œå·¦å¯¹é½ */
    table th:first-child,
    table td:first-child {
      text-align: left;
    }
    /* ç¬¬ 2 åˆ—ï¼šMethodï¼Œå·¦å¯¹é½ */
    table th:nth-child(2),
    table td:nth-child(2) {
      text-align: left;
    }
    /* ä»ç¬¬ 3 åˆ—å¼€å§‹ï¼ˆæ•°å€¼åˆ—ï¼‰ï¼Œç›®å‰è®¾ä¸ºå·¦å¯¹é½ï¼Œå¦‚æœæƒ³å³å¯¹é½æŠŠ left æ”¹æˆ right */
    table th:nth-child(n + 3),
    table td:nth-child(n + 3) {
      text-align: left;
    }
    
    code, pre {
      font-family: SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      font-size: 0.85rem;
      background-color: #f5f5f5;
    }
    pre {
      padding: 12px;
      border-radius: 6px;
      overflow-x: auto;
    }
    footer {
      text-align: center;
      padding: 16px;
      font-size: 0.8rem;
      color: #777;
    }
    .pill-note {
      font-size: 0.85rem;
      color: #666;
      margin-top: 4px;
    }

    @media (max-width: 600px) {
      .hero h1 {
        font-size: 2rem;
      }
      .hero h3 {
        font-size: 1.05rem;
      }
    }
    
  </style>
</head>
<body>
  <header>
    <div class="container">
      <!-- é¡¶éƒ¨å¯¼èˆªå·²åˆ é™¤ -->

      <!-- é¡¹ç›®æ ‡é¢˜ & ä½œè€…ä¿¡æ¯ -->
      <div class="hero">
        <h1>ğŸŒŸ DiverseVAR</h1>
        <h3>Diversity Has Always Been There in Your Visual Autoregressive Models</h3>

        <div class="authors">
          <a href="https://wangtong627.github.io/">Tong Wang</a><sup>1,2</sup>,
          <a href="https://cs.seu.edu.cn/gyyang/main.htm">Guanyu Yang</a><sup>1</sup>,
          <a href="https://sites.google.com/site/liunian228/">Nian Liu</a><sup>2</sup>,
          <a href="https://wangkai930418.github.io/">Kai Wang</a><sup>3</sup>,
          <a href="https://yaxingwang.github.io/">Yaxing Wang</a><sup>4</sup>,
          <a href="https://amshaker.github.io/">Abdelrahman M Shaker</a><sup>2</sup>,
          <br>
          <a href="https://salman-h-khan.github.io/">Salman Khan</a><sup>2</sup>,
          <a href="https://sites.google.com/view/fahadkhans/home">Fahad Shahbaz Khan</a><sup>2</sup>,
          <a href="https://sen-mao.github.io/">Senmao Li</a><sup>4,2</sup>
        </div>

        <div class="affiliations">
          <sup>1</sup> Southeast University &nbsp;Â·&nbsp;
          <sup>2</sup> MBZUAI &nbsp;Â·&nbsp;
          <sup>3</sup> City University of Hong Kong &nbsp;Â·&nbsp;
          <sup>4</sup> Nankai University
        </div>

        <div class="badges">
          <!-- arXiv badge -->
          <a href="https://arxiv.org/abs/2511.17074" target="_blank" rel="noopener">
            <img src="https://img.shields.io/badge/arXiv-2511.17074-red" alt="arXiv 2511.17074">
          </a>

          <!-- GitHub Repo badge -->
          <a href="https://github.com/wangtong627/DiverseVAR" target="_blank" rel="noopener">
            <img src="https://img.shields.io/badge/Code-Repository-F9D371?logo=github" alt="GitHub Repo">
          </a>
        </div>
      </div>
    </div>
  </header>

  <main>
    <div class="container">

      <!-- Introduction -->
      <section id="intro">
        <h2>ğŸ’¡ Introduction</h2>
        <p>
          We introduce <strong>DiverseVAR</strong>, a simple yet highly effective approach to restore the
          <strong>generative diversity</strong> of <strong>Visual Autoregressive (VAR)</strong> models
          <strong>without any additional training</strong>.
        </p>

        <p>
          Despite their advantages in inference efficiency and image quality, VAR models frequently suffer from
          the well-known <strong>"diversity collapse"</strong>, leading to a reduction in output variability,
          analogous to that observed in few-step distilled diffusion models. Through a thorough analysis of
          pre-trained VAR models, we found that:
        </p>

        <ul>
          <li><strong>Structure formation predominantly occurs in the early scales</strong>.</li>
          <li><strong>Diversity is primarily governed by a "pivotal component" within these early scales</strong>.</li>
        </ul>

        <p>
          DiverseVAR leverages these findings by strategically intervening on the pivotal components during the
          inference process to unlock the inherent generative potential of VAR models.
        </p>
      </section>

      <!-- Method -->
      <section id="method">
        <h2>ğŸ› ï¸ Method Overview</h2>
        <p>
          The DiverseVAR framework introduces two complementary, training-free regularization steps during
          inference, both focusing on the manipulation of the pivotal components:
        </p>

        <ol>
          <li>
            <strong>Soft-Suppression Regularization (SSR):</strong>
            <ul>
              <li>Applied to the model's <strong>input feature map</strong> at early scales.</li>
              <li>Mitigates diversity collapse by suppressing the dominant singular values (our proxy for the pivotal component).</li>
            </ul>
          </li>
          <li>
            <strong>Soft-Amplification Regularization (SAR):</strong>
            <ul>
              <li>Applied to the model's <strong>output feature map</strong>.</li>
              <li>Aims to further promote controlled diversity and improve image-text alignment, especially for numerical attributes.</li>
            </ul>
          </li>
        </ol>

        <p>
          This training-free framework effectively boosts generative diversity while maintaining high-fidelity
          synthesis and faithful semantic alignment.
        </p>

        <!-- DiverseVAR æ€»ä½“æ¡†æ¶ç¤ºæ„å›¾ -->
        <div class="figure">
          <img src="Framework_DiverseVAR.png" alt="The overall framework of DiverseVAR">
          <div>
            Figure 1. The overall framework of DiverseVAR. Diversity is encouraged at early scales,
            while the standard VAR inference process is preserved at later scales.
          </div>
        </div>
      </section>

      <!-- Qualitative -->
      <section id="qualitative">
      <h2>ğŸ–¼ï¸ Qualitative Results</h2>
      <p>
        The figure below illustrates the enhanced generative diversity achieved by our DiverseVAR (2nd and 4th rows)
        compared to the vanilla VAR models (1st and 3rd rows). Our method produces a wider variety of realistic images
        while preserving high-quality and strong text-image alignment.
      </p>
    
      <!-- ä¸»æ–‡ qualitative å›¾ -->
      <div class="figure">
        <img src="DiverseVAR.png" alt="DiverseVAR Qualitative Results">
        <div>
          Figure 2. Multiple generation samples from the vanilla VAR models (1st and 3rd rows)
          and our DiverseVAR (2nd and 4th rows).
        </div>
      </div>
    
      <!-- ä¸»æ–‡ prompts -->
      <p class="pill-note">
        Prompts used in Figure 2: â€œA man in a clown mask eating a donutâ€, â€œA cat wearing a Halloween costumeâ€,
        â€œGolden Gate Bridge at sunset, glowing sky, ...â€, â€œA palace under the sunsetâ€,
        â€œA cool astronaut floating in spaceâ€, and â€œA cat riding a skateboard down a hillâ€.
      </p>
    
    
      <!-- Supplemental Figure 3 (S1) -->
      <div class="figure">
        <img src="sup_figure1_main_samples_a_compressed.png" alt="Additional diversity comparison A">
        <div>
          Figure 3. Additional diversity comparison. Our results demonstrate superior diversity.
        </div>
      </div>
    
      <p class="pill-note">
        Prompts used in Figure 3: â€œA very cute cat near a bunch of birdsâ€, â€œA cat standing on a hillâ€,
        â€œA photo of a cute rabbit holding a cup of coffee in a cafeâ€, â€œA cinematic shot of a little pig priest wearing sunglassesâ€,
        â€œA dog covered in vinesâ€, and â€œCute grey cat, digital oil painting by Monetâ€.
      </p>
    
    
      <!-- Supplemental Figure 4 (S2) -->
      <div class="figure">
        <img src="sup_figure1_main_samples_b_compressed.png" alt="Additional diversity comparison B">
        <div>
          Figure 4. Additional diversity comparison. Our results demonstrate superior diversity.
        </div>
      </div>
    
      <p class="pill-note">
        Prompts used in Figure 4: â€œEditorial photoshoot of an old woman, high fashion 2000s fashionâ€,
        â€œAn astronaut riding a horse on the moon, oil painting by Van Goghâ€,
        â€œFull body shot, a French woman, photography, French streetsâ€, â€œA boy and a girl fall in loveâ€,
        â€œAn abstract portrait of a pensive face, rendered in cool shades of blues, purples, and graysâ€,
        and â€œCute boy, hair looking up to the stars, snow, beautiful lighting, painting style by Abe Toshiyukiâ€.
      </p>
    
    
      <!-- Supplemental Figure 5 (S3) -->
      <div class="figure">
        <img src="sup_figure1_main_samples_c_compressed.png" alt="Additional diversity comparison C">
        <div>
          Figure 5. Additional diversity comparison. Our results demonstrate superior diversity.
        </div>
      </div>
    
      <p class="pill-note">
        Prompts used in Figure 5: â€œA table with a light on over itâ€, â€œA library filled with warm yellow lightâ€,
        â€œA villa standing on a hillâ€, â€œA train crossing a bridge over a canyonâ€,
        â€œA bridge stretching over a calm riverâ€, and â€œA temple surrounded by flowersâ€.
      </p>
    
    </section>

      <!-- Quantitative -->
      <section id="quantitative">
        <h2>ğŸ“Š Quantitative Results (COCO Benchmarks)</h2>
        <p>
          The table below demonstrates that our DiverseVAR significantly improves diversity metrics
          (<em>Recall â†‘</em>, <em>Cov. â†‘</em>, <em>FID â†“</em>) while maintaining comparable
          <em>CLIPScore (CLIP â†‘)</em> on the COCO2014-30K and COCO2017-5K benchmarks.
        </p>

        <table>
          <thead>
            <tr>
              <th>Dataset</th>
              <th>Method</th>
              <th>Recall â†‘</th>
              <th>Cov. â†‘</th>
              <th>FID â†“</th>
              <th>CLIP â†‘</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="4"><strong>COCO2014-30K</strong></td>
              <td>Infinity-2B</td>
              <td>0.316</td>
              <td>0.651</td>
              <td>28.48</td>
              <td>0.313</td>
            </tr>
            <tr>
              <td><strong>+Ours (DiverseVAR)</strong></td>
              <td><strong>0.385</strong></td>
              <td><strong>0.690</strong></td>
              <td><strong>22.96</strong></td>
              <td>0.313</td>
            </tr>
            <tr>
              <td>Infinity-8B</td>
              <td>0.451</td>
              <td>0.740</td>
              <td>18.79</td>
              <td>0.319</td>
            </tr>
            <tr>
              <td><strong>+Ours (DiverseVAR)</strong></td>
              <td><strong>0.497</strong></td>
              <td><strong>0.748</strong></td>
              <td><strong>14.26</strong></td>
              <td>0.315</td>
            </tr>

            <tr>
              <td rowspan="4"><strong>COCO2017-5K</strong></td>
              <td>Infinity-2B</td>
              <td>0.408</td>
              <td>0.832</td>
              <td>39.01</td>
              <td>0.313</td>
            </tr>
            <tr>
              <td><strong>+Ours (DiverseVAR)</strong></td>
              <td><strong>0.480</strong></td>
              <td><strong>0.860</strong></td>
              <td><strong>33.39</strong></td>
              <td>0.313</td>
            </tr>
            <tr>
              <td>Infinity-8B</td>
              <td>0.563</td>
              <td>0.892</td>
              <td>29.47</td>
              <td>0.319</td>
            </tr>
            <tr>
              <td><strong>+Ours (DiverseVAR)</strong></td>
              <td><strong>0.585</strong></td>
              <td>0.892</td>
              <td><strong>25.01</strong></td>
              <td>0.316</td>
            </tr>
          </tbody>
        </table>

        <p class="pill-note">
          â†‘: Higher is better. â†“: Lower is better.
        </p>
      </section>

      <!-- Citation -->
      <section id="citation">
        <h2>ğŸ“„ Citation</h2>
        <p>
          Please cite our paper if you find this work useful for your research:
        </p>

        <pre><code>@article{wang2025diversity,
  title   = {Diversity Has Always Been There in Your Visual Autoregressive Models},
  author  = {Wang, Tong and Yang, Guanyu and Liu, Nian and Wang, Kai and Wang, Yaxing and Shaker, Abdelrahman M and Khan, Salman and Khan, Fahad Shahbaz and Li, Senmao},
  journal = {arXiv preprint arXiv:2511.17074},
  year    = {2025}
}</code></pre>
      </section>

    </div>
  </main>

  <footer>
    Copyright Â© Tong Wang et al.
  </footer>
</body>
</html>
